centr<-centraYescala(procTrain,procTest)
procTrain<-centr[[1]]
procTest<-centr[[2]]
new_ts <- model.matrix(~.+0,data = procTest)
dtest <- xgb.DMatrix(data = new_ts,label = targTe)
new_tr <- model.matrix(~.+0,data = procTrain)
dtrain <- xgb.DMatrix(data = new_tr,label = targTr)
rm(dat,procTrain,procTest,centr,train,test)
gc()
library(Metrics)
library(Amelia)
library(purrr)
library(Amelia)
library(dplyr)
library(caret)
library(doMC)
library(randomForest)
library(modelgrid)
library(xgboost)
new_ts <- model.matrix(~.+0,data = procTest)
dtest <- xgb.DMatrix(data = new_ts,label = targTe)
new_tr <- model.matrix(~.+0,data = procTrain)
dtrain <- xgb.DMatrix(data = new_tr,label = targTr)
rm(dat,procTrain,procTest,centr,train,test)
gc()
importRF<-function(x,y){
isW<-Sys.info()[1]=="Windows"
datUnid<-x
datUnid$targ<-y
if(isW){
library(doParallel)
library(foreach)
cl<-makeCluster(10)
registerDoParallel(cl)
modelo_randforest <- foreach(ntree=rep(100, 10), .combine=randomForest::combine, .multicombine=TRUE,
.packages='randomForest') %dopar% {
mod<-randomForest(formula = targ ~ . ,
data = datUnid,
mtry = dim(datUnid)[2],
importance = TRUE,
ntree = ntree)
cat("esto aca",mod$importance,"\n", file="pruebisjeje.txt",append=TRUE)
mod
}
importancia <- as.data.frame(modelo_randforest$importance)
stopCluster(cl)
importancia$var<-row.names(importancia)
importancia[order(importancia[,1],decreasing = TRUE),]
}
else{
}
}
a<-rnorm(1000)
b<-rnorm(1000)
c<-rnorm(1000)
d<-rnorm(1000)
y<-a*b+c³
y<-a*b+c^3
x<-data.frame(a,b,c,d)
yas<-importRF(x,y)
head(yas)
Pablo Portillo <pabportillo@gmail.com>
21:01 (hace 1 minuto)
para mí
importRF<-function(x,y){
isW<-Sys.info()[1]=="Windows"
isW<-TRUE
datUnid<-x
datUnid$targ<-y
if(isW){
library(doParallel)
library(foreach)
cl<-makeCluster(10)
registerDoParallel(cl)
modelo_randforest <- foreach(ntree=rep(100, 10), .combine=randomForest::combine, .multicombine=TRUE,
.packages='randomForest') %dopar% {
mod<-randomForest(formula = targ ~ . ,
data = datUnid,
mtry = dim(datUnid)[2],
importance = TRUE,
ntree = ntree)
cat("esto aca",mod$importance,"\n", file="pruebisjeje.txt",append=TRUE)
mod
}
importancia <- as.data.frame(modelo_randforest$importance)
stopCluster(cl)
importancia$var<-row.names(importancia)
importancia[order(importancia[,1],decreasing = TRUE),]
}
else{
}
}
head(yas)
yas<-importRF(x,y)
yas
yas[order(yas$IncNodePurity)]
yas[order(yas$IncNodePurity),]
library(lightgbm)
a<-rnorm(100000)
b<-rnorm(100000)
c<-rnorm(100000)
d<-rnorm(100000)
e<-rnorm(100000)
f<-rnorm(100000)
g<-rnorm(100000)
h<-rnorm(100000)
i<-rnorm(100000)
y<-a*b+c*d-e*f^2+3*g^3
dat<-as.matrix(a,b,c,d,e,f,g,h,i)
class(dat)
library(tictoc)
lgb.train = lgb.Dataset(data=dat, label=y)
lgb.grid = list(objective = "regression",
metric = "mae",
min_sum_hessian_in_leaf = 1,
feature_fraction = 0.7,
bagging_fraction = 0.7,
bagging_freq = 5,
min_data = 100,
max_bin = 50,
lambda_l1 = 8,
lambda_l2 = 1.3,
min_data_in_bin=100,
min_gain_to_split = 10,
min_data_in_leaf = 30)
lgb.model = lgb.train(params = lgb.grid, data = lgb.train, learning_rate = 0.02,
num_leaves = 25, num_threads = 4 , eval = "mae"
lgb.model = lgb.train(params = lgb.grid, data = lgb.train, learning_rate = 0.02,
num_leaves = 25, num_threads = 4 , eval = "mae")
lgb.model
MAE(predict(lgb.model,lgb.train),y)
library(MLmetrics)
MAE(predict(lgb.model,lgb.train),y)
MAE(predict(lgb.model,dat),y)
lgb.model = lgb.train(params = lgb.grid, data = lgb.train, learning_rate = 0.02,
num_leaves = 25, device_tipe="gpu" , eval = "mae")
MAE(predict(lgb.model,dat),y)
lgb.model = lgb.train(params = lgb.grid, data = lgb.train, learning_rate = 0.02,
num_leaves = 25, num_threads = 2 , eval = "mae")
train-read.csv("Escritorio/Kaggle/Santander/train.csv")
train<-read.csv("Escritorio/Kaggle/Santander/train.csv")
cvId<-sample(1:10,nrow(train),replace=TRUE)
train<-read.csv("Escritorio/Kaggle/Santander/train.csv")
cvId<-sample(1:10,nrow(train),replace=TRUE)
test<-train[cvId==1,]
train<-train[cvId!=1,]
train.y<-train$target
test.y<-test$target
train<-train[,-c(1,2)]
test<-test[,-c(1,2)]
lgb.grid = list(objective = "binary",
metric = "auc",
min_sum_hessian_in_leaf = 1,
feature_fraction = 0.7,
bagging_fraction = 0.7,
bagging_freq = 5,
min_data = 100,
max_bin = 50,
lambda_l1 = 8,
lambda_l2 = 1.3,
min_data_in_bin=100,
min_gain_to_split = 10,
min_data_in_leaf = 30,
is_unbalance = TRUE)
lgb.train = lgb.Dataset(data=train, label=train.y)
lgb.train = lgb.Dataset(data=train, label=train.y)
lgb.model = lgb.train(params = lgb.grid, data = lgb.train, learning_rate = 0.02,
num_leaves = 25, num_threads = 2 ,
eval_freq = 20, eval = "error")
lgb.train = lgb.Dataset(data=as.matrix(train), label=train.y)
lgb.model = lgb.train(params = lgb.grid, data = lgb.train, learning_rate = 0.02,
num_leaves = 25, num_threads = 2 ,
eval_freq = 20, eval = "error")
lgb.model = lgb.train(params = lgb.grid, data = lgb.train, learning_rate = 0.02,
num_leaves = 25, num_threads = 2 ,
eval_freq = 20, eval = "auc")
AUC(predict(lgb.model,as.matrix(test)),test.y)
lgb.model = lgb.train(params = lgb.grid, data = lgb.train, learning_rate = 0.02,
num_leaves = 25, num_threads = 4 ,
eval_freq = 20, eval = "auc")
lgb.model = lgb.train(params = lgb.grid, data = lgb.train, learning_rate = 0.02,
num_leaves = 25, num_threads = 2 ,
eval_freq = 20, eval = "auc")
train<-read.csv("Escritorio/Kaggle/Santander/SMOTEsantander/trainSyn1.csv")
colnames(train)
test<-read.csv("Escritorio/Kaggle/Santander/SMOTEsantander/test1.csv")
train.y<-train$class
colnames(test)
test.y<-test$target
train<-train[,-ncol(train)]
test<-test[,-c(1,2,ncol(test))]
colnames(train)
colnames(test)
lgb.train = lgb.Dataset(data=as.matrix(train), label=train.y)
lgb.model = lgb.train(params = lgb.grid, data = lgb.train, learning_rate = 0.02,
num_leaves = 25, num_threads = 4 ,
eval_freq = 20, eval = "auc")
AUC(predict(lgb.model,as.matrix(test)),test.y)
lgb.model = lgb.train(params = lgb.grid, data = lgb.train, learning_rate = 0.02,
num_leaves = 25, num_threads = 8 ,
eval_freq = 20, eval = "auc")
lgb.model = lgb.train(params = lgb.grid, data = lgb.train, learning_rate = 0.02,
num_leaves = 25, num_threads = 123 ,
eval_freq = 20, eval = "auc")
lgb.model = lgb.train(params = lgb.grid, data = lgb.train, learning_rate = 0.02,
num_leaves = 25, num_threads = 4 ,
eval_freq = 20, eval = "auc")
head(predict(lgb.model,as.matrix(test)))
head(round(predict(lgb.model,as.matrix(test))))
sumd(round(predict(lgb.model,as.matrix(test))))
sum(round(predict(lgb.model,as.matrix(test))))
any(predict(lgb.model,as.matrix(test))>0.5)
any(predict(lgb.model,as.matrix(test))>0.4)
sum(predict(lgb.model,as.matrix(test))>0.4)
lgb.grid = list(objective = "binary",
metric = "auc",
min_sum_hessian_in_leaf = 1,
feature_fraction = 0.7,
bagging_fraction = 0.7,
bagging_freq = 5,
min_data = 100,
max_bin = 50,
lambda_l1 = 8,
lambda_l2 = 1.3,
min_data_in_bin=100,
min_gain_to_split = 10,
min_data_in_leaf = 30)
lgb.model = lgb.train(params = lgb.grid, data = lgb.train, learning_rate = 0.02,
num_leaves = 25, num_threads = 4 ,
eval_freq = 20, eval = "auc")
any(predict(lgb.model,as.matrix(test))>0.5)
AUC(predict(lgb.model,as.matrix(test)),test.y)
devtools::install_github("Laurae2/lgbdl")
lgb.dl(commit = "master",
libdll = "/home/papis/R/x86_64-pc-linux-gnu-library/3.5/lightgbm/libs/lib_lightgbm.so", # YOUR PRECOMPILED DLL
repo = "https://github.com/Microsoft/LightGBM",
use_gpu = TRUE)
library(lightgbm)
lgb.dl(commit = "master",
libdll = "/home/papis/R/x86_64-pc-linux-gnu-library/3.5/lightgbm/libs/lib_lightgbm.so", # YOUR PRECOMPILED DLL
repo = "https://github.com/Microsoft/LightGBM",
use_gpu = TRUE)
library(lightgbm)
lgb.dl(commit = "master",
libdll = "/home/papis/R/x86_64-pc-linux-gnu-library/3.5/lightgbm/libs/lib_lightgbm.so", # YOUR PRECOMPILED DLL
repo = "https://github.com/Microsoft/LightGBM",
use_gpu = TRUE)
library(lgbdl)
lgb.dl(commit = "master",
libdll = "/home/papis/R/x86_64-pc-linux-gnu-library/3.5/lightgbm/libs/lib_lightgbm.so", # YOUR PRECOMPILED DLL
repo = "https://github.com/Microsoft/LightGBM",
use_gpu = TRUE)
remove.packages("xgboost")
library(xgboost)
X<-as.data.frame(matrix(rnorm(100000),ncol=10))
y<-X$V1*X$V2+X$V3*X$V4-X$V5
library(h2o4gpu)
setwd("Escritorio/willItBurn-/copiaBot/burnItBot/reader/wholeDat/")
library(data.table)
dat<-fread("whole4Momento.csv",data.table = FALSE)
dat[790877,]$id
dat[790877,]$title
dim(dat)
dat<-dat[dat$title!="",]
dim(dat)
dat[790877,]$title
dat[790877,]$id
unique(dat[dat$title==dat[790877,]$title,]$id)
dat<-dat[dat$id!="c2r5zf",]
dim(dart)
dim(dat)
dat<-dat[790877:norw(dat),]
dat<-dat[790877:nrow(dat),]
dim(dat)
dtitle <- paste("title = ", dat$title)
dauthor <- paste("author = ", dat$author)
dedited <- paste("edited = ", dat$edited)
dis_self <- paste("is_self = ", dat$is_self)
dlocked <- paste("locked = ", dat$locked)
dspoiler <- paste("spoiler = ", dat$spoiler)
dstickied <- paste("stickied = ", dat$stickied)
dscore <- paste("score = ", dat$score)
dupvote_ratio <- paste("upvote_ratio = ", dat$upvote_ratio)
did <- paste("id = ", dat$id)
dsubreddit <- paste("subreddit = ", dat$subreddit)
durl <- paste("url = ", dat$url)
dnum_comments <- paste("num_comments = ", dat$num_comments)
dbody <- paste("body = ", dat$body)
dcreated <- paste("created = ", dat$created)
dmeasured <- paste("measured = ", dat$measured)
clauseString <- paste0("rownames = '", rownames(dat), "'")
updateString <- paste0("UPDATE rawDat
SET ",
dtitle, ", ",
dauthor, ", ",
dedited, ", ",
dis_self, ", ",
dlocked, ", ",
dspoiler, ", ",
dscore, ", ",
dupvote_ratio, ", ",
did, ", ",
dsubreddit, ", ",
durl, ", ",
dnum_comments, ", ",
dbody, ", ",
dcreated, ", ",
dmeasured,
" WHERE " , clauseString)
updateString[1]
dbhandle <- odbcDriverConnect('driver=/opt/microsoft/msodbcsql17/lib64/libmsodbcsql-17.3.so.1.1;server=localhost;database=BurnItBot;uid=SA;pwd=Infinito10.50.3')
library(RODBC)
dbhandle <- odbcDriverConnect('driver=/opt/microsoft/msodbcsql17/lib64/libmsodbcsql-17.3.so.1.1;server=localhost;database=BurnItBot;uid=SA;pwd=Infinito10.50.3')
sqlQuery(dbhandle, updateString)
updateString[1]
rownames(dat)<-paste0(dat$id,dat$measured)
dtitle <- paste("title = ", dat$title)
dauthor <- paste("author = ", dat$author)
dedited <- paste("edited = ", dat$edited)
dis_self <- paste("is_self = ", dat$is_self)
dlocked <- paste("locked = ", dat$locked)
dspoiler <- paste("spoiler = ", dat$spoiler)
dstickied <- paste("stickied = ", dat$stickied)
dscore <- paste("score = ", dat$score)
dupvote_ratio <- paste("upvote_ratio = ", dat$upvote_ratio)
did <- paste("id = ", dat$id)
dsubreddit <- paste("subreddit = ", dat$subreddit)
durl <- paste("url = ", dat$url)
dnum_comments <- paste("num_comments = ", dat$num_comments)
dbody <- paste("body = ", dat$body)
dcreated <- paste("created = ", dat$created)
dmeasured <- paste("measured = ", dat$measured)
clauseString <- paste0("rownames = '", rownames(dat), "'")
updateString <- paste0("UPDATE rawDat
SET ",
dtitle, ", ",
dauthor, ", ",
dedited, ", ",
dis_self, ", ",
dlocked, ", ",
dspoiler, ", ",
dscore, ", ",
dupvote_ratio, ", ",
did, ", ",
dsubreddit, ", ",
durl, ", ",
dnum_comments, ", ",
dbody, ", ",
dcreated, ", ",
dmeasured,
" WHERE " , clauseString)
updateString[1]
library(odbc)
con <- dbConnect(odbc(), Driver = "/opt/microsoft/msodbcsql17/lib64/libmsodbcsql-17.3.so.1.1",
Server = "", Database = "BurnItBot", UID = "SA", PWD = "Infinito10.50.3",
Port = 1433)
dim(dat)
dbWriteTable(conn = con,
name = "rawDat",
value = dat,
append=TRUE,
row.names=TRUE)
dbWriteTable(conn = con,
name = "rawDat",
value = dat,
append=TRUE,
row_names=TRUE)
dbWriteTable(conn = con,
name = "rawDat",
value = dat,
append=TRUE,
row_names="rownames")
dbWriteTable(conn = con,
name = "rawDat",
value = dat,
append=TRUE,
rownames=TRUE)
dbWriteTable(conn = con,
name = "rawDat",
value = dat,
append=TRUE,
row.names=TRUE)
sqlUpdate(dbhandle, dat, tablename = "rawDat")
sqlUpdate(dbhandle, dat, tablename = "rawDat")
sqlUpdate(dbhandle, dat, tablename = "rawDat",verbose = TRUE)
dat[1,c("id","title")]
getwd(ç)
getwd()
setwd("..")
temp = list.files(pattern="reader")
temp = paste(temp,"/post.csv",sep="")
temp
myfiles = lapply(temp,function(x){ fread(x,data.table=FALSE)])
myfiles = lapply(temp,function(x){ fread(x,data.table=FALSE)})
length(myfiles)
dim(myfiles[[1]])
dim(myfiles[[2]])
dat<-myfiles[[1]]
for(i in 2:length(myfiles)){
dat<-rbind(dat,myfiles[[iº]])
}
dat<-myfiles[[1]]
for(i in 2:length(myfiles)){
dat<-rbind(dat,myfiles[[i]])
}
dim(dat)
rownames(dat)<-paste0(dat$id,dat$measured)
dim(dat)
sum(duplicated(du
sum(duplicated(row.names(dat)))
dim(dat)
dat[329671,]<-dat[329670,]
sum(duplicated(row.names(dat)))
rownames(dat)<-paste0(dat$id,dat$measured)
dim(dat)
dat[329671,]<-dat[329670,]
dim(dat)
dat[329671,]<-dat[329670,]
dim(dat)
rownames(dat)<-paste0(dat$id,dat$measured)
dim(dat)
rownames(dat)<-paste0(dat$id,dat$measured)
setwd("wholeDat/")
aux<-fread("wholeDat.csv",data.table=FALSE)
rownames(aux)<-paste0(aux$id,aux$measured)
dat<-[!(rownames(dat) %in% rownames(aux)),]
dat<-dat
dat<-dat[!(rownames(dat) %in% rownames(aux)),]
dim(dat)
dim(aux)
aux[171696,]<-dat[392670,]
rownames(aux)<-paste0(aux$id,aux$measured)
dat<-dat[!(rownames(dat) %in% rownames(aux)),]
dim(dat)
getwd()
a<-fread("wholeDat.csv",data.table = FALSE)
b<-fread("whosHot.csv",data.table = FALSE)
sum(unique(a$id) %in% unique(b$id)/length(unique(a$id))
sum(unique(a$id) %in% unique(b$id))/length(unique(a$id))
c<-fread("rawTrain.csv",data.table = FALSE)
sum(unique(c$id) %in% unique(b$id))/length(unique(c$id))
d<-fread("whosHot (copia).csv",data.table = FALSE)
e<-fread("datast/whosHot.csv",data.table = FALSE)
f<-fread("datast/whosHot2.csv",data.table = FALSE)
g<-fread("datast/whosHotN.csv",data.table = FALSE)
hot<-rbind(d,e,f,g)
sum(unique(c$id) %in% unique(hot$id))/length(unique(c$id))
sum(unique(a$id) %in% unique(hot$id))/length(unique(a$id))
write.csv("whosHot.csv",x=hot,row.names = FALSE)
dim(hot)
length(unique(hot$id))
hot<-as.data.frame(hot %>% grouping())
library(dplyr)
hot<-as.data.frame(hot %>% group_by(id) %>% summarise(time=min(time)))
dim(hot)
write.csv("whosHot.csv",x=hot,row.names = FALSE)
write.csv("whosHot.csv",x=hot,row.names = FALSE)
yas<-read.csv("whosHot.csv")
dim(yas)
length(unique(yas$id))
a<-fread("wholeDat.csv",data.table = FALSE)
a<-fread("wholeDat.csv",data.table = FALSE)
b<-fread("whosHot.csv",data.table = FALSE)
head(b)
sum(unique(a$id) %in% unique(b$id))/length(unique(a$id))
length(unique(a$id))
dim(a)
a<-fread("wholeDat.csv",data.table = FALSE)
dim(a)
sum(unique(a$id) %in% unique(b$id))/length(unique(a$id))
length(unique(a$id))
?write.csv
a<-fread("wholeDat.csv",data.table = FALSE)
dim(a)
unique(a$id)
length(unique(a$id))
dim(a)
ids<-paste(a$id,a$measured)
length(ids)
length(unique(ids))
a<-fread("wholeDat.csv",data.table = FALSE)
dim(a)
write.csv("wholeDat.csv",x=a,row.names = FALSE)
object.size(a)
389663224/(*)
389663224/(1024*1024)
write.csv("wholeDat.csv",x=a,row.names = FALSE)
file.size(a)
fwrite(x=a,file = "wholeDat.csv")
a<-fread("wholeDat.csv",data.table = FALSE)
dim(A)
dim(a)
length(unique(a$id))
a<-fread("wholeDat.csv",data.table = FALSE)
dim(a)
length(unique(a$id))
b<-fread("whosHot.csv",data.table = FALSE
b<-fread("whosHot.csv",data.table = FALSE)
sum(unique(a$id) %in% unique(b$id))/length(unique(a$id))
a<-fread("wholeDat.csv",data.table = FALSE)
dim(a)
a<-fread("wholeDat.csv",data.table = FALSE)
dim(a)
length(unique(a$id))
a<-fread("wholeDat.csv",data.table = FALSE)
dim(a)
A
a
a[1,]
a<-fread("wholeDat.csv",data.table = FALSE)
dim(a)
length(unique(a$id))
